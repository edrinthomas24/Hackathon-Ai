{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edrinthomas24/Hackathon-Ai/blob/main/crowd_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WUSn0v4WnNh",
        "outputId": "fd396e68-cf59-4755-c790-c9d4595a44a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.75-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting twilio\n",
            "  Downloading twilio-9.4.5-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.10.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.11/dist-packages (from twilio) (3.11.12)\n",
            "Collecting aiohttp-retry>=2.8.3 (from twilio)\n",
            "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.25.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Downloading ultralytics-8.3.75-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading twilio-9.4.5-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m913.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, aiohttp-retry, twilio, ultralytics-thop, streamlit, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiohttp-retry-2.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydeck-0.9.1 streamlit-1.42.0 twilio-9.4.5 ultralytics-8.3.75 ultralytics-thop-2.0.14 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics opencv-python numpy flask streamlit matplotlib twilio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdIsROIDWvQw",
        "outputId": "f23e60dd-e0f1-4fc3-b645-5798081060e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 19.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # 'n' stands for Nano model (lightweight)\n",
        "\n",
        "# Print model details\n",
        "print(\"YOLO model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "idcy-kUlYTK0",
        "outputId": "749229ae-895a-4413-b0b2-0601583f7f93"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow # Import the necessary function\n",
        "\n",
        "# Load YOLOv8 model (Pre-trained on COCO dataset)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Load the pre-recorded video\n",
        "video_path = \"/content/WhatsApp Video 2025-02-13 at 10.44.43_248db3db.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(frame)\n",
        "\n",
        "    # Extract person detections\n",
        "    people_count = sum(1 for obj in results[0].boxes.data if int(obj[5]) == 0)  # COCO class 0 = 'person'\n",
        "\n",
        "    # Determine zone status\n",
        "    if people_count < 5:\n",
        "        zone_status = \"Green (Safe)\"\n",
        "        color = (0, 255, 0)\n",
        "    elif people_count < 15:\n",
        "        zone_status = \"Yellow (Caution)\"\n",
        "        color = (0, 255, 255)\n",
        "    else:\n",
        "        zone_status = \"Red (Danger)\"\n",
        "        color = (0, 0, 255)\n",
        "\n",
        "    # Draw results on frame\n",
        "    for box in results[0].boxes.data:\n",
        "        x1, y1, x2, y2, conf, cls = map(int, box)\n",
        "        if cls == 0:  # Only draw boxes for 'person'\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "    # Display crowd status\n",
        "    cv2.putText(frame, f\"Zone: {zone_status} ({people_count} people)\", (30, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3)\n",
        "\n",
        "    cv2_imshow(frame) # Use cv2_imshow instead of cv2.imshow\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djqfYqNWYgmw",
        "outputId": "b8a7d283-2222-4395-8054-cdb8ddd70644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/yolo_detection.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python yolo_detection.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzbnDjKHYlaK",
        "outputId": "05113f44-8303-4b36-86d6-1c5ad0998b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 139.5ms\n",
            "Speed: 4.4ms preprocess, 139.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 161.6ms\n",
            "Speed: 4.7ms preprocess, 161.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 2 umbrellas, 171.7ms\n",
            "Speed: 4.6ms preprocess, 171.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 2 umbrellas, 192.2ms\n",
            "Speed: 4.7ms preprocess, 192.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 2 umbrellas, 159.1ms\n",
            "Speed: 4.6ms preprocess, 159.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 2 umbrellas, 1 sports ball, 150.1ms\n",
            "Speed: 4.6ms preprocess, 150.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 163.0ms\n",
            "Speed: 4.7ms preprocess, 163.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 19 persons, 1 umbrella, 211.5ms\n",
            "Speed: 4.7ms preprocess, 211.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 1 umbrella, 273.9ms\n",
            "Speed: 4.5ms preprocess, 273.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 1 boat, 1 umbrella, 251.8ms\n",
            "Speed: 5.4ms preprocess, 251.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 1 umbrella, 284.4ms\n",
            "Speed: 7.3ms preprocess, 284.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 146.7ms\n",
            "Speed: 4.8ms preprocess, 146.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 1 umbrella, 163.0ms\n",
            "Speed: 7.1ms preprocess, 163.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 152.4ms\n",
            "Speed: 5.3ms preprocess, 152.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 176.6ms\n",
            "Speed: 6.0ms preprocess, 176.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 161.6ms\n",
            "Speed: 5.1ms preprocess, 161.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 164.8ms\n",
            "Speed: 6.1ms preprocess, 164.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 160.3ms\n",
            "Speed: 4.6ms preprocess, 160.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 1 umbrella, 160.3ms\n",
            "Speed: 4.7ms preprocess, 160.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 162.0ms\n",
            "Speed: 7.7ms preprocess, 162.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 149.8ms\n",
            "Speed: 4.8ms preprocess, 149.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 164.7ms\n",
            "Speed: 4.9ms preprocess, 164.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 366.5ms\n",
            "Speed: 13.0ms preprocess, 366.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 umbrella, 157.7ms\n",
            "Speed: 4.6ms preprocess, 157.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 152.8ms\n",
            "Speed: 5.1ms preprocess, 152.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 249.0ms\n",
            "Speed: 7.0ms preprocess, 249.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 294.8ms\n",
            "Speed: 4.6ms preprocess, 294.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 250.2ms\n",
            "Speed: 6.8ms preprocess, 250.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 umbrella, 168.1ms\n",
            "Speed: 4.6ms preprocess, 168.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 155.1ms\n",
            "Speed: 4.7ms preprocess, 155.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 182.2ms\n",
            "Speed: 4.8ms preprocess, 182.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 153.8ms\n",
            "Speed: 4.5ms preprocess, 153.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 157.3ms\n",
            "Speed: 5.7ms preprocess, 157.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 150.1ms\n",
            "Speed: 7.4ms preprocess, 150.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 168.7ms\n",
            "Speed: 4.7ms preprocess, 168.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 umbrella, 183.2ms\n",
            "Speed: 5.4ms preprocess, 183.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 1 umbrella, 153.4ms\n",
            "Speed: 5.9ms preprocess, 153.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 umbrella, 170.7ms\n",
            "Speed: 4.8ms preprocess, 170.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 umbrella, 169.3ms\n",
            "Speed: 5.8ms preprocess, 169.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 umbrella, 156.8ms\n",
            "Speed: 4.7ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 154.7ms\n",
            "Speed: 4.6ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 152.9ms\n",
            "Speed: 4.6ms preprocess, 152.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 umbrella, 164.3ms\n",
            "Speed: 4.7ms preprocess, 164.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 155.2ms\n",
            "Speed: 6.0ms preprocess, 155.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 177.0ms\n",
            "Speed: 5.1ms preprocess, 177.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 1 umbrella, 150.5ms\n",
            "Speed: 4.7ms preprocess, 150.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 256.8ms\n",
            "Speed: 6.3ms preprocess, 256.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 261.5ms\n",
            "Speed: 4.7ms preprocess, 261.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 259.8ms\n",
            "Speed: 7.3ms preprocess, 259.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 152.7ms\n",
            "Speed: 4.9ms preprocess, 152.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 168.3ms\n",
            "Speed: 12.9ms preprocess, 168.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 179.2ms\n",
            "Speed: 5.0ms preprocess, 179.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 10 persons, 1 umbrella, 147.0ms\n",
            "Speed: 4.8ms preprocess, 147.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 10 persons, 1 umbrella, 160.5ms\n",
            "Speed: 4.8ms preprocess, 160.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 175.8ms\n",
            "Speed: 4.7ms preprocess, 175.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 158.7ms\n",
            "Speed: 6.4ms preprocess, 158.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 186.4ms\n",
            "Speed: 8.0ms preprocess, 186.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 146.2ms\n",
            "Speed: 5.0ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 147.9ms\n",
            "Speed: 4.6ms preprocess, 147.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 10 persons, 1 umbrella, 150.6ms\n",
            "Speed: 5.5ms preprocess, 150.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 10 persons, 164.6ms\n",
            "Speed: 5.1ms preprocess, 164.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 160.0ms\n",
            "Speed: 6.0ms preprocess, 160.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 151.1ms\n",
            "Speed: 5.0ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 166.0ms\n",
            "Speed: 4.6ms preprocess, 166.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 172.0ms\n",
            "Speed: 4.7ms preprocess, 172.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 156.7ms\n",
            "Speed: 4.8ms preprocess, 156.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 1 horse, 257.2ms\n",
            "Speed: 4.5ms preprocess, 257.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 244.0ms\n",
            "Speed: 5.3ms preprocess, 244.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 263.5ms\n",
            "Speed: 5.1ms preprocess, 263.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 boat, 277.3ms\n",
            "Speed: 7.3ms preprocess, 277.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 189.1ms\n",
            "Speed: 4.5ms preprocess, 189.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 155.5ms\n",
            "Speed: 4.5ms preprocess, 155.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 173.6ms\n",
            "Speed: 4.4ms preprocess, 173.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 1 boat, 1 umbrella, 159.8ms\n",
            "Speed: 4.7ms preprocess, 159.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 boat, 157.7ms\n",
            "Speed: 4.4ms preprocess, 157.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 12 persons, 1 boat, 1 umbrella, 149.0ms\n",
            "Speed: 4.5ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 11 persons, 1 boat, 1 umbrella, 165.6ms\n",
            "Speed: 5.3ms preprocess, 165.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 boat, 2 umbrellas, 156.7ms\n",
            "Speed: 4.7ms preprocess, 156.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 2 umbrellas, 147.6ms\n",
            "Speed: 4.6ms preprocess, 147.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 2 umbrellas, 177.0ms\n",
            "Speed: 5.5ms preprocess, 177.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 2 umbrellas, 160.2ms\n",
            "Speed: 4.6ms preprocess, 160.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 2 umbrellas, 154.9ms\n",
            "Speed: 7.5ms preprocess, 154.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 1 boat, 2 umbrellas, 147.6ms\n",
            "Speed: 4.5ms preprocess, 147.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 boat, 152.0ms\n",
            "Speed: 5.0ms preprocess, 152.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 1 boat, 1 umbrella, 167.9ms\n",
            "Speed: 4.7ms preprocess, 167.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 1 umbrella, 158.2ms\n",
            "Speed: 7.2ms preprocess, 158.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 1 boat, 1 umbrella, 162.8ms\n",
            "Speed: 5.6ms preprocess, 162.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 boat, 1 umbrella, 232.1ms\n",
            "Speed: 5.7ms preprocess, 232.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 1 umbrella, 314.2ms\n",
            "Speed: 4.6ms preprocess, 314.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 umbrella, 1 sports ball, 256.8ms\n",
            "Speed: 11.2ms preprocess, 256.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 umbrella, 1 sports ball, 170.1ms\n",
            "Speed: 5.1ms preprocess, 170.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 157.8ms\n",
            "Speed: 4.9ms preprocess, 157.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 160.7ms\n",
            "Speed: 4.7ms preprocess, 160.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 13 persons, 163.9ms\n",
            "Speed: 9.5ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 158.8ms\n",
            "Speed: 5.3ms preprocess, 158.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 1 boat, 144.1ms\n",
            "Speed: 6.9ms preprocess, 144.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 164.2ms\n",
            "Speed: 5.5ms preprocess, 164.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 157.1ms\n",
            "Speed: 5.8ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 boat, 167.0ms\n",
            "Speed: 4.7ms preprocess, 167.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 169.0ms\n",
            "Speed: 4.4ms preprocess, 169.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 180.3ms\n",
            "Speed: 5.1ms preprocess, 180.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 155.7ms\n",
            "Speed: 4.4ms preprocess, 155.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 164.6ms\n",
            "Speed: 4.8ms preprocess, 164.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 165.8ms\n",
            "Speed: 5.1ms preprocess, 165.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 165.1ms\n",
            "Speed: 7.4ms preprocess, 165.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 152.7ms\n",
            "Speed: 4.6ms preprocess, 152.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 158.2ms\n",
            "Speed: 4.5ms preprocess, 158.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 238.5ms\n",
            "Speed: 4.6ms preprocess, 238.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 243.0ms\n",
            "Speed: 15.5ms preprocess, 243.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 22 persons, 226.3ms\n",
            "Speed: 5.0ms preprocess, 226.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 176.4ms\n",
            "Speed: 5.8ms preprocess, 176.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 151.1ms\n",
            "Speed: 4.5ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 170.1ms\n",
            "Speed: 4.5ms preprocess, 170.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 165.7ms\n",
            "Speed: 5.2ms preprocess, 165.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 151.9ms\n",
            "Speed: 5.2ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 177.3ms\n",
            "Speed: 11.5ms preprocess, 177.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 172.3ms\n",
            "Speed: 4.7ms preprocess, 172.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 156.5ms\n",
            "Speed: 5.4ms preprocess, 156.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 158.4ms\n",
            "Speed: 5.1ms preprocess, 158.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 1 sports ball, 154.8ms\n",
            "Speed: 5.2ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 170.5ms\n",
            "Speed: 4.8ms preprocess, 170.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 150.7ms\n",
            "Speed: 6.2ms preprocess, 150.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 19 persons, 155.1ms\n",
            "Speed: 4.6ms preprocess, 155.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 sports ball, 151.7ms\n",
            "Speed: 5.2ms preprocess, 151.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 sports ball, 182.9ms\n",
            "Speed: 5.3ms preprocess, 182.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 22 persons, 1 sports ball, 151.6ms\n",
            "Speed: 5.1ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 sports ball, 160.7ms\n",
            "Speed: 6.3ms preprocess, 160.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 sports ball, 149.5ms\n",
            "Speed: 4.6ms preprocess, 149.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 sports ball, 248.5ms\n",
            "Speed: 5.7ms preprocess, 248.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 28 persons, 267.5ms\n",
            "Speed: 13.6ms preprocess, 267.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 29 persons, 250.1ms\n",
            "Speed: 7.4ms preprocess, 250.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 31 persons, 208.2ms\n",
            "Speed: 8.2ms preprocess, 208.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 28 persons, 156.3ms\n",
            "Speed: 6.8ms preprocess, 156.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 27 persons, 158.4ms\n",
            "Speed: 5.5ms preprocess, 158.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 30 persons, 147.6ms\n",
            "Speed: 5.1ms preprocess, 147.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 148.6ms\n",
            "Speed: 6.9ms preprocess, 148.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 159.1ms\n",
            "Speed: 4.7ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 151.7ms\n",
            "Speed: 4.7ms preprocess, 151.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 24 persons, 147.3ms\n",
            "Speed: 5.2ms preprocess, 147.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 155.5ms\n",
            "Speed: 7.6ms preprocess, 155.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 22 persons, 161.3ms\n",
            "Speed: 5.0ms preprocess, 161.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 159.5ms\n",
            "Speed: 4.6ms preprocess, 159.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 161.3ms\n",
            "Speed: 6.1ms preprocess, 161.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 159.5ms\n",
            "Speed: 4.6ms preprocess, 159.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 188.6ms\n",
            "Speed: 4.9ms preprocess, 188.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 24 persons, 162.9ms\n",
            "Speed: 4.7ms preprocess, 162.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 148.8ms\n",
            "Speed: 4.5ms preprocess, 148.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 151.3ms\n",
            "Speed: 7.4ms preprocess, 151.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 245.6ms\n",
            "Speed: 4.5ms preprocess, 245.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 244.5ms\n",
            "Speed: 17.7ms preprocess, 244.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 260.0ms\n",
            "Speed: 14.4ms preprocess, 260.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 243.9ms\n",
            "Speed: 8.9ms preprocess, 243.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 164.8ms\n",
            "Speed: 5.5ms preprocess, 164.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 149.3ms\n",
            "Speed: 4.7ms preprocess, 149.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 17 persons, 158.4ms\n",
            "Speed: 4.9ms preprocess, 158.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 158.5ms\n",
            "Speed: 4.6ms preprocess, 158.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 169.1ms\n",
            "Speed: 4.6ms preprocess, 169.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 177.8ms\n",
            "Speed: 4.9ms preprocess, 177.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 152.0ms\n",
            "Speed: 5.2ms preprocess, 152.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 146.4ms\n",
            "Speed: 7.3ms preprocess, 146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 165.0ms\n",
            "Speed: 5.5ms preprocess, 165.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 15 persons, 155.0ms\n",
            "Speed: 5.3ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 14 persons, 149.4ms\n",
            "Speed: 5.7ms preprocess, 149.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 152.5ms\n",
            "Speed: 4.6ms preprocess, 152.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 16 persons, 157.8ms\n",
            "Speed: 4.7ms preprocess, 157.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 155.1ms\n",
            "Speed: 4.7ms preprocess, 155.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 19 persons, 160.2ms\n",
            "Speed: 9.6ms preprocess, 160.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 traffic light, 157.7ms\n",
            "Speed: 5.2ms preprocess, 157.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 179.8ms\n",
            "Speed: 4.6ms preprocess, 179.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 traffic light, 237.2ms\n",
            "Speed: 7.3ms preprocess, 237.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 traffic light, 241.9ms\n",
            "Speed: 14.4ms preprocess, 241.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 22 persons, 1 traffic light, 247.3ms\n",
            "Speed: 7.3ms preprocess, 247.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 245.9ms\n",
            "Speed: 11.9ms preprocess, 245.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 18 persons, 156.8ms\n",
            "Speed: 4.7ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 19 persons, 152.1ms\n",
            "Speed: 4.6ms preprocess, 152.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 19 persons, 146.7ms\n",
            "Speed: 4.6ms preprocess, 146.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 traffic light, 172.1ms\n",
            "Speed: 4.7ms preprocess, 172.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 19 persons, 1 traffic light, 154.4ms\n",
            "Speed: 5.1ms preprocess, 154.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 traffic light, 145.5ms\n",
            "Speed: 4.8ms preprocess, 145.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 1 traffic light, 199.3ms\n",
            "Speed: 5.0ms preprocess, 199.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 164.7ms\n",
            "Speed: 4.7ms preprocess, 164.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 1 boat, 1 traffic light, 172.1ms\n",
            "Speed: 4.7ms preprocess, 172.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 1 traffic light, 149.9ms\n",
            "Speed: 6.2ms preprocess, 149.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 1 traffic light, 146.8ms\n",
            "Speed: 5.8ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 24 persons, 1 traffic light, 167.2ms\n",
            "Speed: 4.7ms preprocess, 167.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 1 traffic light, 155.4ms\n",
            "Speed: 4.5ms preprocess, 155.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 1 traffic light, 144.2ms\n",
            "Speed: 4.6ms preprocess, 144.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 153.0ms\n",
            "Speed: 6.3ms preprocess, 153.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 24 persons, 166.1ms\n",
            "Speed: 4.8ms preprocess, 166.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 24 persons, 150.7ms\n",
            "Speed: 5.6ms preprocess, 150.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 22 persons, 266.5ms\n",
            "Speed: 4.8ms preprocess, 266.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 246.7ms\n",
            "Speed: 6.2ms preprocess, 246.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 1 traffic light, 228.0ms\n",
            "Speed: 7.8ms preprocess, 228.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 30 persons, 1 traffic light, 163.7ms\n",
            "Speed: 7.2ms preprocess, 163.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 28 persons, 1 traffic light, 177.5ms\n",
            "Speed: 5.0ms preprocess, 177.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 148.4ms\n",
            "Speed: 6.7ms preprocess, 148.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 158.4ms\n",
            "Speed: 6.9ms preprocess, 158.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 28 persons, 161.2ms\n",
            "Speed: 4.8ms preprocess, 161.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 29 persons, 156.2ms\n",
            "Speed: 5.5ms preprocess, 156.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 25 persons, 148.9ms\n",
            "Speed: 4.9ms preprocess, 148.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 154.0ms\n",
            "Speed: 5.4ms preprocess, 154.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 23 persons, 144.0ms\n",
            "Speed: 5.9ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 22 persons, 182.5ms\n",
            "Speed: 4.7ms preprocess, 182.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 26 persons, 149.1ms\n",
            "Speed: 4.6ms preprocess, 149.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 20 persons, 168.1ms\n",
            "Speed: 6.7ms preprocess, 168.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 21 persons, 152.6ms\n",
            "Speed: 5.8ms preprocess, 152.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from datetime import datetime\n",
        "from scipy.spatial import ConvexHull\n",
        "\n",
        "# Load YOLOv8 model (Pre-trained on COCO dataset)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Load the pre-recorded video\n",
        "video_path = \"/content/VID2.mp4\"\n",
        "\n",
        "if not os.path.exists(video_path):\n",
        "    print(f\"❌ Error: Video file '{video_path}' not found.\")\n",
        "    exit()\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"❌ Error: Cannot open video file.\")\n",
        "    exit()\n",
        "\n",
        "# Get input video properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "if fps == 0 or frame_width == 0 or frame_height == 0:\n",
        "    print(\"❌ Error: Could not retrieve video properties.\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "# Set up output video writer\n",
        "output_video_path = \"output_dashboard.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width * 2, frame_height))\n",
        "\n",
        "if not output_video.isOpened():\n",
        "    print(\"❌ Error: VideoWriter failed to open!\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "# Log file for alerts\n",
        "alert_log_path = \"alert_log.txt\"\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(frame)\n",
        "\n",
        "    # Extract person detections (bounding box centers)\n",
        "    people_boxes = [\n",
        "        ((int((box[0] + box[2]) / 2)), (int((box[1] + box[3]) / 2)))\n",
        "        for box in results[0].boxes.data.cpu().numpy() if int(box[5]) == 0  # Class 0 = 'person'\n",
        "    ]\n",
        "\n",
        "    people_count = len(people_boxes)\n",
        "\n",
        "    # Default area assumption for low counts\n",
        "    occupied_area = 50000  # Default minimum area if fewer than 3 people detected\n",
        "\n",
        "    if people_count >= 3:\n",
        "        points = np.array(people_boxes)  # Convert to NumPy array\n",
        "        hull = ConvexHull(points)  # Compute convex hull\n",
        "        occupied_area = hull.volume  # Hull area (approximated)\n",
        "\n",
        "    # Compute density (people per pixel squared)\n",
        "    density = people_count / occupied_area if occupied_area > 0 else 0\n",
        "\n",
        "    # Set density thresholds\n",
        "    SAFE_DENSITY = 0.0005\n",
        "    CAUTION_DENSITY = 0.0015\n",
        "    DANGER_DENSITY = 0.0025\n",
        "\n",
        "    # Determine zone status based on density\n",
        "    if density < SAFE_DENSITY:\n",
        "        zone_status = \"Green (Safe)\"\n",
        "        color = (0, 255, 0)  # Green\n",
        "        scatter_color = \"green\"\n",
        "    elif density < CAUTION_DENSITY:\n",
        "        zone_status = \"Yellow (Caution)\"\n",
        "        color = (0, 255, 255)  # Yellow\n",
        "        scatter_color = \"yellow\"\n",
        "    else:\n",
        "        zone_status = \"Red (Danger)\"\n",
        "        color = (0, 0, 255)  # Red\n",
        "        scatter_color = \"red\"\n",
        "\n",
        "        # Log alert when danger zone is detected\n",
        "        alert_message = f\"🚨 ALERT: High crowd density detected! (People: {people_count}, Density: {density:.5f}) - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        print(alert_message)  # Print in console\n",
        "        with open(alert_log_path, \"a\") as log_file:\n",
        "            log_file.write(alert_message)\n",
        "\n",
        "    # Draw bounding boxes on the frame\n",
        "    for box in results[0].boxes.data.cpu().numpy():\n",
        "        x1, y1, x2, y2, conf, cls = box.astype(int)\n",
        "        if cls == 0:  # Only draw boxes for 'person'\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "    # Display crowd status on video\n",
        "    cv2.putText(frame, f\"Zone: {zone_status} | Density: {density:.5f}\", (30, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3)\n",
        "\n",
        "    # Generate scatter plot as an image\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    ax.set_xlim(0, frame.shape[1])  # X-axis based on frame width\n",
        "    ax.set_ylim(frame.shape[0], 0)  # Y-axis based on frame height (inverted)\n",
        "    ax.set_title(f\"Crowd Density Map: {zone_status}\")\n",
        "    ax.set_xlabel(\"X Coordinate\")\n",
        "    ax.set_ylabel(\"Y Coordinate\")\n",
        "\n",
        "    # Plot people positions\n",
        "    if people_boxes:\n",
        "        x_vals, y_vals = zip(*people_boxes)\n",
        "        ax.scatter(x_vals, y_vals, c=scatter_color, s=50, alpha=0.7)\n",
        "\n",
        "    # Save scatter plot as an image\n",
        "    scatter_path = \"scatter_plot.jpg\"\n",
        "    plt.savefig(scatter_path, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Read scatter plot as an image\n",
        "    scatter_img = cv2.imread(scatter_path)\n",
        "\n",
        "    if scatter_img is None:\n",
        "        print(\"❌ Error: Failed to load scatter plot image.\")\n",
        "        break\n",
        "\n",
        "    scatter_img = cv2.resize(scatter_img, (frame_width, frame_height))\n",
        "\n",
        "    # Combine video frame & scatter plot side by side\n",
        "    combined_frame = np.hstack((frame, scatter_img))\n",
        "\n",
        "    # Write frame to output video\n",
        "    output_video.write(combined_frame)\n",
        "\n",
        "cap.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"✅ Dashboard video saved at: {output_video_path}\")\n",
        "print(f\"📄 Alerts logged in: {alert_log_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmIQCt60c5xS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "99de7f2a-2de6-4c56-ebac-ab309c03ca4a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/output_dashboard.mp4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-19019b945b9e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/output_dashboard.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/output_dashboard.mp4"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "video_path = \"/content/output_dashboard.mp4\"\n",
        "files.download(video_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists(\"/content/VID2.mp4\"))  # Should return True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t5ks1wOhna1",
        "outputId": "5e8aa3d0-5a41-422f-d196-d6e8dacb1b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJKrLgXy5wox"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}